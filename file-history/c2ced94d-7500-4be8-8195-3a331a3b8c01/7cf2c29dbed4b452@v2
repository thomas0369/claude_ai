name: ğŸš€ Advanced Backtesting & Optimization

on:
  workflow_dispatch:
    inputs:
      start_date:
        description: 'Start Date (YYYY-MM-DD)'
        required: false
        default: '2024-01-01'
      end_date:
        description: 'End Date (YYYY-MM-DD)'
        required: false
        default: '2025-01-01'
      run_optimization:
        description: 'Run parameter optimization'
        type: boolean
        default: false
  schedule:
    # Run every Sunday at 02:00 UTC (monthly comprehensive backtest)
    - cron: '0 2 * * 0'
  pull_request:
    branches: [ main ]
    paths:
      - 'src/screener.py'
      - 'src/indicators.py'
      - 'scripts/backtest_*.py'

permissions:
  contents: write
  pull-requests: write
  issues: write
  discussions: write

jobs:
  multi-timeframe-backtest:
    name: ğŸ”¬ Multi-Timeframe Validation
    runs-on: ubuntu-latest

    steps:
      - name: ğŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ğŸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: ğŸ“¦ Install Dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: ğŸ”¬ Run Multi-Timeframe Backtest
        env:
          CAPITAL_API_KEY: ${{ secrets.CAPITAL_API_KEY }}
          CAPITAL_API_SECRET: ${{ secrets.CAPITAL_API_SECRET }}
          CAPITAL_PASSWORD: ${{ secrets.CAPITAL_PASSWORD }}
          DEMO_MODE: 'true'
        run: |
          python scripts/multi_timeframe_backtest.py \
            --start-date ${{ github.event.inputs.start_date || '2024-01-01' }} \
            --end-date ${{ github.event.inputs.end_date || '2025-01-01' }}

      - name: ğŸ“Š Generate Performance Report
        run: |
          python scripts/generate_backtest_report.py \
            --input data/timeframe_comparison.json \
            --output reports/backtest_report_$(date +%Y%m%d).md

      - name: ğŸ“¤ Upload Results
        uses: actions/upload-artifact@v4
        with:
          name: backtest-results-${{ github.run_number }}
          path: |
            data/backtest_*.json
            data/timeframe_comparison.json
            reports/*.md
          retention-days: 90

      - name: ğŸ’¬ Post Results to Discussion
        if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('reports/backtest_report_$(date +%Y%m%d).md', 'utf8');

            await github.rest.discussions.createDiscussion({
              owner: context.repo.owner,
              repo: context.repo.repo,
              category_slug: 'performance-analytics',
              title: `ğŸ“Š Backtest Results - ${new Date().toISOString().split('T')[0]}`,
              body: report
            });

      - name: ğŸ“Š Update Performance Badge
        run: |
          python scripts/update_performance_badge.py \
            --input data/timeframe_comparison.json

  parameter-optimization:
    name: ğŸ¯ Parameter Optimization
    runs-on: ubuntu-latest
    if: github.event.inputs.run_optimization == 'true' || github.event_name == 'schedule'

    steps:
      - name: ğŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ğŸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: ğŸ“¦ Install Dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install optuna optuna-dashboard

      - name: ğŸ¯ Run Bayesian Optimization
        env:
          CAPITAL_API_KEY: ${{ secrets.CAPITAL_API_KEY }}
          CAPITAL_API_SECRET: ${{ secrets.CAPITAL_API_SECRET }}
          CAPITAL_PASSWORD: ${{ secrets.CAPITAL_PASSWORD }}
          DEMO_MODE: 'true'
        run: |
          python scripts/optimize_strategy_v2.py \
            --n-trials 100 \
            --timeframe 1h \
            --output data/optimization_results.json

      - name: ğŸ“ˆ Generate Optimization Report
        run: |
          python scripts/generate_optimization_report.py \
            --input data/optimization_results.json \
            --output reports/optimization_report.md

      - name: ğŸ’¾ Commit Optimized Parameters
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add data/optimization_results.json
          git commit -m "ğŸ¯ Update optimized parameters - $(date +%Y-%m-%d)" || echo "No changes"
          git push

      - name: ğŸ“¤ Upload Optimization Results
        uses: actions/upload-artifact@v4
        with:
          name: optimization-results-${{ github.run_number }}
          path: |
            data/optimization_results.json
            reports/optimization_report.md
          retention-days: 90

  monte-carlo-simulation:
    name: ğŸ² Monte Carlo Risk Analysis
    runs-on: ubuntu-latest
    needs: [multi-timeframe-backtest]

    steps:
      - name: ğŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ğŸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: ğŸ“¦ Install Dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install scipy

      - name: ğŸ² Run Monte Carlo Simulation
        run: |
          python scripts/monte_carlo_simulation.py \
            --input data/backtest_1h_trades.json \
            --simulations 10000 \
            --output data/monte_carlo_results.json

      - name: ğŸ“Š Generate Risk Report
        run: |
          python scripts/generate_risk_report.py \
            --input data/monte_carlo_results.json \
            --output reports/risk_analysis.md

      - name: ğŸ“¤ Upload Risk Analysis
        uses: actions/upload-artifact@v4
        with:
          name: risk-analysis-${{ github.run_number }}
          path: |
            data/monte_carlo_results.json
            reports/risk_analysis.md
          retention-days: 90

  performance-regression-check:
    name: âš ï¸ Performance Regression Check
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    needs: [multi-timeframe-backtest]

    steps:
      - name: ğŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ğŸ“¥ Download Baseline
        uses: actions/download-artifact@v4
        with:
          name: baseline-performance
          path: data/baseline

      - name: ğŸ” Compare Performance
        run: |
          python scripts/compare_performance.py \
            --baseline data/baseline/backtest_results.json \
            --current data/backtest_1h_results.json \
            --threshold 0.05

      - name: ğŸ’¬ Comment on PR
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: 'âš ï¸ **Performance Regression Detected**\n\nThe changes in this PR result in worse backtest performance. Please review before merging.'
            })

  deploy-results-to-pages:
    name: ğŸ“Š Deploy Results to GitHub Pages
    runs-on: ubuntu-latest
    needs: [multi-timeframe-backtest, monte-carlo-simulation]
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'

    steps:
      - name: ğŸ“¥ Checkout gh-pages
        uses: actions/checkout@v4
        with:
          ref: gh-pages

      - name: ğŸ“¥ Download Artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts

      - name: ğŸ“Š Generate Interactive Dashboard
        run: |
          python scripts/generate_performance_dashboard.py \
            --backtest artifacts/backtest-results-*/backtest_*.json \
            --monte-carlo artifacts/risk-analysis-*/monte_carlo_results.json \
            --output performance/index.html

      - name: ğŸ’¾ Commit and Push
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add performance/
          git commit -m "ğŸ“Š Update performance dashboard - $(date +%Y-%m-%d)"
          git push

  notify-telegram:
    name: ğŸ“± Send Telegram Notification
    runs-on: ubuntu-latest
    needs: [multi-timeframe-backtest]
    if: always() && (github.event_name == 'schedule' || github.event_name == 'workflow_dispatch')

    steps:
      - name: ğŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ğŸ“Š Extract Results
        id: results
        run: |
          BEST_TF=$(jq -r '.best_timeframe' data/timeframe_comparison.json)
          ANNUAL_RETURN=$(jq -r ".results.$BEST_TF.annual_return" data/timeframe_comparison.json)
          WIN_RATE=$(jq -r ".results.$BEST_TF.win_rate" data/timeframe_comparison.json)
          SHARPE=$(jq -r ".results.$BEST_TF.sharpe_ratio" data/timeframe_comparison.json)

          echo "best_tf=$BEST_TF" >> $GITHUB_OUTPUT
          echo "annual_return=$ANNUAL_RETURN" >> $GITHUB_OUTPUT
          echo "win_rate=$WIN_RATE" >> $GITHUB_OUTPUT
          echo "sharpe=$SHARPE" >> $GITHUB_OUTPUT

      - name: ğŸ“± Send to Telegram
        uses: appleboy/telegram-action@master
        with:
          to: ${{ secrets.TELEGRAM_CHAT_ID }}
          token: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          format: markdown
          message: |
            ğŸ“Š *Backtest Results Update*

            ğŸ† *Best Timeframe:* ${{ steps.results.outputs.best_tf }}
            ğŸ“ˆ *Annual Return:* ${{ steps.results.outputs.annual_return }}%
            âœ… *Win Rate:* ${{ steps.results.outputs.win_rate }}%
            ğŸ“Š *Sharpe Ratio:* ${{ steps.results.outputs.sharpe }}

            [View Full Report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
