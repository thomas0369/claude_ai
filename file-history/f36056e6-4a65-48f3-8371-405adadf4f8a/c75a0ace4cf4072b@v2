"""
Data Quality Assessment Framework for Elliott Wave Trading Bot.

Provides comprehensive quality scoring (0-100) for market data with:
- Candle count completeness (25 points)
- Data freshness (25 points)
- Gap analysis (20 points)
- OHLC integrity validation (15 points)
- Volume validity (15 points)

Quality Levels:
- EXCELLENT: 90-100
- GOOD: 75-89
- FAIR: 60-74
- POOR: 0-59
"""

import pandas as pd
import numpy as np
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Optional, Tuple
import logging

logger = logging.getLogger(__name__)


class DataQualityAssessment:
    """
    Comprehensive data quality assessment with scoring and recommendations.

    Metrics:
    1. Completeness (25 pts): Candle count vs. target
    2. Freshness (25 pts): How recent is the data
    3. Gaps (20 pts): Missing data periods
    4. OHLC Integrity (15 pts): Price data validation
    5. Volume (15 pts): Volume data quality
    """

    # Quality thresholds
    QUALITY_LEVELS = {
        "EXCELLENT": (90, 100, "ðŸŸ¢"),
        "GOOD": (75, 89, "ðŸŸ¡"),
        "FAIR": (60, 74, "ðŸŸ "),
        "POOR": (0, 59, "ðŸ”´")
    }

    # Scoring weights
    WEIGHTS = {
        "completeness": 25,
        "freshness": 25,
        "gaps": 20,
        "integrity": 15,
        "volume": 15
    }

    def __init__(self):
        pass

    def assess_quality(
        self,
        symbol: str,
        timeframe: str,
        df: pd.DataFrame,
        metadata: Optional[Dict] = None,
        target_candles: int = 2400
    ) -> Dict:
        """
        Calculate comprehensive quality score for market data.

        Args:
            symbol: Asset symbol (e.g., "EUR/USD")
            timeframe: Timeframe (e.g., "5m", "1h")
            df: DataFrame with OHLCV data
            metadata: Optional cache metadata
            target_candles: Target candle count

        Returns:
            Quality assessment dict with score and breakdown
        """
        logger.info(f"Assessing quality for {symbol} {timeframe}")

        # Calculate individual scores
        completeness_score, completeness_details = self._assess_completeness(
            df, target_candles
        )

        freshness_score, freshness_details = self._assess_freshness(
            df, metadata
        )

        gaps_score, gaps_details = self._assess_gaps(
            df, timeframe
        )

        integrity_score, integrity_details = self._assess_ohlc_integrity(df)

        volume_score, volume_details = self._assess_volume_quality(df)

        # Calculate total score
        total_score = sum([
            completeness_score,
            freshness_score,
            gaps_score,
            integrity_score,
            volume_score
        ])

        # Determine quality level
        quality_level = self._get_quality_level(total_score)

        # Collect issues and recommendations
        issues = []
        recommendations = []

        # Check each metric for issues
        if completeness_score < self.WEIGHTS["completeness"] * 0.8:
            issues.append(completeness_details["issue"])
            recommendations.append(completeness_details["recommendation"])

        if freshness_score < self.WEIGHTS["freshness"] * 0.8:
            issues.append(freshness_details["issue"])
            recommendations.append(freshness_details["recommendation"])

        if gaps_score < self.WEIGHTS["gaps"] * 0.8:
            issues.append(gaps_details["issue"])
            if gaps_details["recommendation"]:
                recommendations.append(gaps_details["recommendation"])

        if integrity_score < self.WEIGHTS["integrity"]:
            issues.append(integrity_details["issue"])
            recommendations.append(integrity_details["recommendation"])

        if volume_score < self.WEIGHTS["volume"] * 0.8:
            issues.append(volume_details["issue"])
            recommendations.append(volume_details["recommendation"])

        return {
            "symbol": symbol,
            "timeframe": timeframe,
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "overall_score": total_score,
            "max_score": 100,
            "status": quality_level["name"],
            "status_emoji": quality_level["emoji"],
            "ready_for_trading": total_score >= 70,
            "breakdown": {
                "completeness": {
                    "score": completeness_score,
                    "max": self.WEIGHTS["completeness"],
                    "percentage": int((completeness_score / self.WEIGHTS["completeness"]) * 100),
                    "status": self._get_metric_status(completeness_score, self.WEIGHTS["completeness"]),
                    "details": completeness_details
                },
                "freshness": {
                    "score": freshness_score,
                    "max": self.WEIGHTS["freshness"],
                    "percentage": int((freshness_score / self.WEIGHTS["freshness"]) * 100),
                    "status": self._get_metric_status(freshness_score, self.WEIGHTS["freshness"]),
                    "details": freshness_details
                },
                "gaps": {
                    "score": gaps_score,
                    "max": self.WEIGHTS["gaps"],
                    "percentage": int((gaps_score / self.WEIGHTS["gaps"]) * 100),
                    "status": self._get_metric_status(gaps_score, self.WEIGHTS["gaps"]),
                    "details": gaps_details
                },
                "integrity": {
                    "score": integrity_score,
                    "max": self.WEIGHTS["integrity"],
                    "percentage": int((integrity_score / self.WEIGHTS["integrity"]) * 100),
                    "status": self._get_metric_status(integrity_score, self.WEIGHTS["integrity"]),
                    "details": integrity_details
                },
                "volume": {
                    "score": volume_score,
                    "max": self.WEIGHTS["volume"],
                    "percentage": int((volume_score / self.WEIGHTS["volume"]) * 100),
                    "status": self._get_metric_status(volume_score, self.WEIGHTS["volume"]),
                    "details": volume_details
                }
            },
            "issues": issues,
            "recommendations": recommendations
        }

    def _assess_completeness(
        self,
        df: pd.DataFrame,
        target_candles: int
    ) -> Tuple[int, Dict]:
        """
        Assess data completeness (25 points max).

        Scoring:
        - 100% of target: 25 points
        - 90-99%: 20 points
        - 80-89%: 15 points
        - 70-79%: 10 points
        - <70%: 5 points
        """
        actual_candles = len(df)
        percentage = (actual_candles / target_candles) * 100

        if percentage >= 100:
            score = 25
            status = "Perfect"
        elif percentage >= 90:
            score = 20
            status = "Excellent"
        elif percentage >= 80:
            score = 15
            status = "Good"
        elif percentage >= 70:
            score = 10
            status = "Fair"
        else:
            score = 5
            status = "Poor"

        details = {
            "actual_candles": actual_candles,
            "target_candles": target_candles,
            "percentage": round(percentage, 1),
            "status": status,
            "issue": f"Only {actual_candles}/{target_candles} candles ({percentage:.0f}%)" if percentage < 100 else None,
            "recommendation": f"Fetch more historical data (need {target_candles - actual_candles} more candles)" if percentage < 90 else None
        }

        return score, details

    def _assess_freshness(
        self,
        df: pd.DataFrame,
        metadata: Optional[Dict]
    ) -> Tuple[int, Dict]:
        """
        Assess data freshness (25 points max).

        Scoring:
        - <5 min: 25 points
        - 5-10 min: 20 points
        - 10-30 min: 15 points
        - 30-60 min: 10 points
        - >60 min: 5 points
        """
        # Get last candle timestamp
        last_timestamp = df.index.max()
        if not isinstance(last_timestamp, pd.Timestamp):
            last_timestamp = pd.to_datetime(last_timestamp)

        # Calculate age
        now = datetime.now(timezone.utc)
        if last_timestamp.tzinfo is None:
            last_timestamp = last_timestamp.tz_localize(timezone.utc)

        age_seconds = (now - last_timestamp).total_seconds()
        age_minutes = age_seconds / 60

        # Score based on age
        if age_minutes < 5:
            score = 25
            status = "Excellent"
        elif age_minutes < 10:
            score = 20
            status = "Good"
        elif age_minutes < 30:
            score = 15
            status = "Fair"
        elif age_minutes < 60:
            score = 10
            status = "Stale"
        else:
            score = 5
            status = "Very Stale"

        # Format age display
        if age_minutes < 60:
            age_display = f"{int(age_minutes)}min"
        else:
            age_display = f"{int(age_minutes / 60)}h {int(age_minutes % 60)}min"

        details = {
            "last_update": last_timestamp.isoformat(),
            "age_seconds": int(age_seconds),
            "age_minutes": round(age_minutes, 1),
            "age_display": age_display,
            "status": status,
            "issue": f"Data is {age_display} old" if age_minutes >= 10 else None,
            "recommendation": "Refresh data for optimal signals" if age_minutes >= 30 else None
        }

        return score, details

    def _assess_gaps(
        self,
        df: pd.DataFrame,
        timeframe: str
    ) -> Tuple[int, Dict]:
        """
        Assess data gaps (20 points max).

        Scoring:
        - 0 gaps: 20 points
        - 1-2 gaps (weekends OK): 15 points
        - 3-5 gaps: 10 points
        - >5 gaps: 5 points
        """
        if len(df) < 2:
            return 20, {"gap_count": 0, "gaps": [], "status": "N/A"}

        # Parse timeframe to minutes
        timeframe_minutes = self._parse_timeframe_minutes(timeframe)
        expected_delta = timedelta(minutes=timeframe_minutes)

        # Find gaps
        time_diffs = df.index.to_series().diff()
        gap_threshold = expected_delta * 1.5

        gaps = []
        for i, (idx, diff) in enumerate(time_diffs.items()):
            if pd.notna(diff) and diff > gap_threshold:
                # Check if weekend gap
                prev_idx = df.index[i - 1]
                is_weekend = self._is_weekend_gap(prev_idx, idx)

                gap_info = {
                    "start": prev_idx.isoformat(),
                    "end": idx.isoformat(),
                    "duration_hours": round(diff.total_seconds() / 3600, 1),
                    "is_weekend": is_weekend
                }
                gaps.append(gap_info)

        # Filter out weekend gaps for scoring
        non_weekend_gaps = [g for g in gaps if not g["is_weekend"]]
        gap_count = len(non_weekend_gaps)

        # Score
        if gap_count == 0:
            score = 20
            status = "Perfect"
        elif gap_count <= 2:
            score = 15
            status = "Good"
        elif gap_count <= 5:
            score = 10
            status = "Fair"
        else:
            score = 5
            status = "Poor"

        details = {
            "gap_count": gap_count,
            "total_gaps": len(gaps),
            "weekend_gaps": len(gaps) - gap_count,
            "gaps": gaps[:5],  # Limit to first 5
            "status": status,
            "issue": f"Detected {gap_count} data gap(s)" if gap_count > 2 else None,
            "recommendation": "Consider re-fetching data to fill gaps" if gap_count > 5 else None
        }

        return score, details

    def _assess_ohlc_integrity(self, df: pd.DataFrame) -> Tuple[int, Dict]:
        """
        Assess OHLC data integrity (15 points max).

        Validates:
        - High >= Low
        - High >= Open
        - High >= Close
        - Low <= Open
        - Low <= Close
        - No NaN values
        """
        violations = 0
        violation_details = []

        # Check for required columns
        required_cols = ["open", "high", "low", "close"]
        if not all(col in df.columns for col in required_cols):
            return 0, {
                "violations": len(required_cols),
                "status": "Missing columns",
                "issue": "Missing required OHLC columns",
                "recommendation": "Re-fetch data"
            }

        # Check NaN values
        nan_count = df[required_cols].isnull().sum().sum()
        if nan_count > 0:
            violations += nan_count
            violation_details.append(f"{nan_count} NaN values found")

        # Validate OHLC relationships
        invalid_high_low = (df["high"] < df["low"]).sum()
        invalid_high_open = (df["high"] < df["open"]).sum()
        invalid_high_close = (df["high"] < df["close"]).sum()
        invalid_low_open = (df["low"] > df["open"]).sum()
        invalid_low_close = (df["low"] > df["close"]).sum()

        violations += sum([
            invalid_high_low,
            invalid_high_open,
            invalid_high_close,
            invalid_low_open,
            invalid_low_close
        ])

        if invalid_high_low > 0:
            violation_details.append(f"{invalid_high_low} candles with High < Low")
        if invalid_high_open > 0:
            violation_details.append(f"{invalid_high_open} candles with High < Open")
        if invalid_high_close > 0:
            violation_details.append(f"{invalid_high_close} candles with High < Close")
        if invalid_low_open > 0:
            violation_details.append(f"{invalid_low_open} candles with Low > Open")
        if invalid_low_close > 0:
            violation_details.append(f"{invalid_low_close} candles with Low > Close")

        # Score (15 points if perfect, deduct for violations)
        if violations == 0:
            score = 15
            status = "Perfect"
        elif violations <= 5:
            score = 10
            status = "Minor issues"
        elif violations <= 10:
            score = 5
            status = "Significant issues"
        else:
            score = 0
            status = "Corrupt data"

        details = {
            "violations": violations,
            "violation_details": violation_details,
            "status": status,
            "issue": f"{violations} OHLC integrity violation(s)" if violations > 0 else None,
            "recommendation": "Re-fetch data to fix integrity issues" if violations > 5 else None
        }

        return score, details

    def _assess_volume_quality(self, df: pd.DataFrame) -> Tuple[int, Dict]:
        """
        Assess volume data quality (15 points max).

        Checks:
        - Volume >= 0 (no negative)
        - Reasonable volume spikes (< 10x average)
        - Not too many zero-volume candles
        """
        if "volume" not in df.columns:
            return 0, {
                "status": "Missing volume data",
                "issue": "Volume column not found",
                "recommendation": "Re-fetch with volume data"
            }

        issues = []

        # Check for negative volume
        negative_count = (df["volume"] < 0).sum()
        if negative_count > 0:
            issues.append(f"{negative_count} negative volume candles")

        # Check for zero volume
        zero_count = (df["volume"] == 0).sum()
        zero_percentage = (zero_count / len(df)) * 100
        if zero_count > 5:
            issues.append(f"{zero_count} zero-volume candles ({zero_percentage:.1f}%)")

        # Check for volume spikes
        avg_volume = df["volume"].mean()
        if avg_volume > 0:
            spike_threshold = avg_volume * 10
            spike_count = (df["volume"] > spike_threshold).sum()
            if spike_count > 0:
                issues.append(f"{spike_count} volume spike(s) > 10x average")

        # Score
        issue_count = len(issues)
        if issue_count == 0:
            score = 15
            status = "Perfect"
        elif issue_count == 1 and "spike" in issues[0]:
            score = 13
            status = "Good (minor spikes)"
        elif issue_count <= 2:
            score = 10
            status = "Fair"
        else:
            score = 5
            status = "Poor"

        details = {
            "negative_count": negative_count,
            "zero_count": zero_count,
            "zero_percentage": round(zero_percentage, 1),
            "avg_volume": round(avg_volume, 2),
            "issues": issues,
            "status": status,
            "issue": "; ".join(issues) if issues else None,
            "recommendation": "Review volume data quality" if issue_count > 2 else None
        }

        return score, details

    def _get_quality_level(self, score: int) -> Dict:
        """Get quality level name and emoji for score."""
        for level, (min_score, max_score, emoji) in self.QUALITY_LEVELS.items():
            if min_score <= score <= max_score:
                return {"name": level, "emoji": emoji, "min": min_score, "max": max_score}
        return {"name": "UNKNOWN", "emoji": "âšª", "min": 0, "max": 0}

    def _get_metric_status(self, score: int, max_score: int) -> str:
        """Get status emoji for individual metric."""
        percentage = (score / max_score) * 100
        if percentage >= 90:
            return "âœ…"
        elif percentage >= 70:
            return "ðŸŸ¡"
        elif percentage >= 50:
            return "ðŸŸ "
        else:
            return "ðŸ”´"

    def _parse_timeframe_minutes(self, timeframe: str) -> int:
        """Parse timeframe string to minutes."""
        timeframe = timeframe.lower()
        if timeframe.endswith('m'):
            return int(timeframe[:-1])
        elif timeframe.endswith('h'):
            return int(timeframe[:-1]) * 60
        elif timeframe.endswith('d'):
            return int(timeframe[:-1]) * 1440
        else:
            raise ValueError(f"Unknown timeframe format: {timeframe}")

    def _is_weekend_gap(self, start: pd.Timestamp, end: pd.Timestamp) -> bool:
        """Check if gap is likely a weekend gap (Friday close to Monday open)."""
        if start.weekday() == 4 and end.weekday() == 0:  # Friday to Monday
            gap_hours = (end - start).total_seconds() / 3600
            if 48 <= gap_hours <= 72:  # Roughly 2-3 days
                return True
        return False


class SystemQualityMonitor:
    """
    Monitor data quality across all symbols and timeframes.

    Provides system-wide quality overview and startup validation.
    """

    def __init__(self, data_cache):
        """
        Initialize system quality monitor.

        Args:
            data_cache: DataCache instance for loading data
        """
        self.data_cache = data_cache
        self.assessor = DataQualityAssessment()

    def assess_all_symbols(
        self,
        symbols: List[str],
        timeframes: List[str],
        target_candles: Dict[str, int] = None
    ) -> Dict:
        """
        Assess quality for all symbols and timeframes.

        Args:
            symbols: List of symbols to assess
            timeframes: List of timeframes to assess
            target_candles: Target candles per timeframe (optional)

        Returns:
            System-wide quality report
        """
        if target_candles is None:
            target_candles = {
                "5m": 2400,
                "15m": 800,
                "1h": 200,
                "4h": 200,
                "1d": 200
            }

        logger.info(f"Assessing quality for {len(symbols)} symbols, {len(timeframes)} timeframes")

        results = {}
        total_score = 0
        total_assessments = 0
        ready_count = 0

        for symbol in symbols:
            results[symbol] = {}

            for timeframe in timeframes:
                # Load data
                df = self.data_cache.load_data(symbol, timeframe)
                metadata = self.data_cache.load_metadata(symbol)

                if df is None or len(df) == 0:
                    # No data available
                    results[symbol][timeframe] = {
                        "overall_score": 0,
                        "status": "NO DATA",
                        "status_emoji": "âš«",
                        "ready_for_trading": False,
                        "error": "No cached data available"
                    }
                    continue

                # Assess quality
                target = target_candles.get(timeframe, 200)
                assessment = self.assessor.assess_quality(
                    symbol, timeframe, df, metadata, target
                )

                results[symbol][timeframe] = assessment

                total_score += assessment["overall_score"]
                total_assessments += 1

                if assessment["ready_for_trading"]:
                    ready_count += 1

        # Calculate system health
        avg_score = total_score / total_assessments if total_assessments > 0 else 0
        ready_percentage = (ready_count / total_assessments) * 100 if total_assessments > 0 else 0

        overall_status = "HEALTHY" if avg_score >= 80 else "DEGRADED" if avg_score >= 60 else "UNHEALTHY"

        return {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "overall_status": overall_status,
            "average_score": round(avg_score, 1),
            "ready_percentage": round(ready_percentage, 1),
            "total_assessments": total_assessments,
            "ready_count": ready_count,
            "symbol_count": len(symbols),
            "timeframe_count": len(timeframes),
            "results": results,
            "system_ready": avg_score >= 70 and ready_percentage >= 75
        }

    def validate_on_startup(
        self,
        symbols: List[str],
        primary_timeframe: str = "5m"
    ) -> Dict:
        """
        Quick quality validation on application startup.

        Only checks primary timeframe (typically 5m) for speed.

        Args:
            symbols: Symbols to validate
            primary_timeframe: Primary timeframe to check

        Returns:
            Startup validation report
        """
        logger.info(f"Running startup quality validation for {len(symbols)} symbols")

        assessment = self.assess_all_symbols(symbols, [primary_timeframe])

        # Generate startup report
        issues = []
        for symbol, timeframes in assessment["results"].items():
            tf_result = timeframes.get(primary_timeframe, {})
            if tf_result.get("overall_score", 0) < 70:
                issues.append({
                    "symbol": symbol,
                    "score": tf_result.get("overall_score", 0),
                    "status": tf_result.get("status", "UNKNOWN"),
                    "issues": tf_result.get("issues", [])
                })

        return {
            "timestamp": assessment["timestamp"],
            "system_ready": assessment["system_ready"],
            "overall_status": assessment["overall_status"],
            "average_score": assessment["average_score"],
            "issues": issues,
            "recommendation": (
                "System ready for trading" if assessment["system_ready"]
                else "Consider refreshing data before trading"
            )
        }
