# DeepSeek TypeScript Migration Plan

**Date:** 2025-11-08
**Status:** PLANNING
**Priority:** HIGH (Python code won't work on Vercel)

---

## Executive Summary

The recently built DeepSeek PDF extraction system (1,206 lines of Python) **cannot be deployed on Vercel**. This document outlines the migration plan to TypeScript/Next.js.

### Key Points

- **Current:** Python scripts (deepseek_vision_client.py, pdf_to_images.py, etc.)
- **Problem:** Vercel serverless doesn't support Python well
- **Solution:** Migrate to TypeScript + Next.js API routes
- **Effort:** 3-5 days
- **Complexity:** MEDIUM (API integration is straightforward)

---

## Current Python Implementation Analysis

### Files to Migrate (1,206 lines total)

```
scripts/
├── deepseek_vision_client.py          (386 lines) ← Core API client
├── pdf_to_images.py                   (162 lines) ← PDF converter
├── step2_pdf_to_json_enhanced.py      (346 lines) ← Extraction orchestrator
├── zerez_pdf_matcher_enhanced.py      (375 lines) ← Matching logic
└── test_deepseek_integration.py       (187 lines) ← Tests
```

### Key Features to Preserve

1. **DeepSeek API Integration:**
   - Rate limiting (60 requests/minute)
   - Cost controls ($1.00 default limit)
   - Retry logic with exponential backoff
   - Error handling
   - Multi-page aggregation

2. **PDF Processing:**
   - PDF to image conversion
   - Multi-page support
   - High-resolution (300 DPI)

3. **Confidence Scoring:**
   - Multi-factor algorithm (5 factors)
   - Configurable threshold
   - Model similarity, manufacturer match, field completeness

4. **Data Storage:**
   - Individual JSON files alongside PDFs
   - Centralized JSON database
   - Metadata tracking

---

## TypeScript Migration Strategy

### Phase 1: Core API Client (2 days)

**Create:** `benchmark-app/lib/deepseek/client.ts`

**Functionality:**
- DeepSeek Vision API integration
- Rate limiting using custom implementation
- Cost tracking
- Retry logic
- Type-safe responses

**Example Structure:**
```typescript
// benchmark-app/lib/deepseek/client.ts
export interface DeepSeekConfig {
  apiKey: string;
  baseUrl?: string;
  maxRequestsPerMinute?: number;
  maxCostUsd?: number;
  timeout?: number;
  retries?: number;
}

export interface ExtractionResult {
  model_name: string;
  manufacturer: string;
  power: {
    rated_power_kw: number | null;
    max_power_kw: number | null;
    continuous_power_kw: number | null;
  };
  // ... other fields
}

export class DeepSeekVisionClient {
  private requestTimes: Date[] = [];
  private totalCost = 0;
  private requestCount = 0;

  constructor(private config: DeepSeekConfig) {}

  async extractFromImage(
    imageBase64: string,
    temperature = 0.1
  ): Promise<ExtractionResult | null> {
    // Rate limiting
    await this.checkRateLimit();

    // Cost check
    const estimatedCost = this.estimateCost(1);
    this.checkCostLimit(estimatedCost);

    // API call with retry
    return this.callApiWithRetry({
      model: 'deepseek-vl2',
      messages: [
        {
          role: 'user',
          content: [
            { type: 'text', text: this.createExtractionPrompt() },
            {
              type: 'image_url',
              image_url: { url: `data:image/png;base64,${imageBase64}` }
            }
          ]
        }
      ],
      temperature,
      max_tokens: 2000
    });
  }

  private async callApiWithRetry(payload: any, attempt = 0): Promise<any> {
    try {
      const response = await fetch(`${this.config.baseUrl}/chat/completions`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.config.apiKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify(payload),
        signal: AbortSignal.timeout(this.config.timeout || 60000)
      });

      if (response.status === 429 && attempt < (this.config.retries || 3)) {
        const waitTime = Math.pow(2, attempt) * 5000;
        await this.sleep(waitTime);
        return this.callApiWithRetry(payload, attempt + 1);
      }

      if (!response.ok) {
        throw new Error(`API error: ${response.status}`);
      }

      const result = await response.json();
      return this.parseResponse(result);
    } catch (error) {
      if (attempt < (this.config.retries || 3)) {
        await this.sleep(2000);
        return this.callApiWithRetry(payload, attempt + 1);
      }
      throw error;
    }
  }

  private checkRateLimit(): Promise<void> {
    const now = new Date();
    const oneMinuteAgo = new Date(now.getTime() - 60000);

    // Remove old requests
    this.requestTimes = this.requestTimes.filter(t => t > oneMinuteAgo);

    // Check limit
    const maxRequests = this.config.maxRequestsPerMinute || 60;
    if (this.requestTimes.length >= maxRequests) {
      const oldestRequest = this.requestTimes[0];
      const sleepTime = 60000 - (now.getTime() - oldestRequest.getTime());
      return this.sleep(sleepTime);
    }

    this.requestTimes.push(now);
    return Promise.resolve();
  }

  private estimateCost(imageCount: number): number {
    const INPUT_TOKENS = 2000;
    const OUTPUT_TOKENS = 500;
    const INPUT_PRICE = 0.14 / 1_000_000;
    const OUTPUT_PRICE = 0.28 / 1_000_000;

    return (INPUT_TOKENS * imageCount * INPUT_PRICE) +
           (OUTPUT_TOKENS * imageCount * OUTPUT_PRICE);
  }

  private checkCostLimit(estimatedCost: number): void {
    const maxCost = this.config.maxCostUsd || 1.0;
    if (this.totalCost + estimatedCost > maxCost) {
      throw new Error(
        `Cost limit exceeded: $${this.totalCost.toFixed(4)} + ` +
        `$${estimatedCost.toFixed(4)} > $${maxCost.toFixed(2)}`
      );
    }
  }

  private sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  private createExtractionPrompt(): string {
    return `Extract technical specifications from this battery energy storage system (BESS) datasheet.

Extract the following information in JSON format:

{
  "model_name": "exact product model name",
  "manufacturer": "manufacturer name",
  "power": {
    "rated_power_kw": number or null,
    "max_power_kw": number or null,
    "continuous_power_kw": number or null
  },
  // ... rest of schema
}

Rules:
- Extract only values explicitly stated in the document
- Use null for missing values
- Extract numeric values without units
- Return ONLY valid JSON, no additional text`;
  }

  private parseResponse(result: any): ExtractionResult | null {
    if (!result.choices?.[0]?.message?.content) {
      return null;
    }

    let content = result.choices[0].message.content;

    // Extract JSON from markdown code blocks
    if (content.includes('```json')) {
      content = content.split('```json')[1].split('```')[0];
    } else if (content.includes('```')) {
      content = content.split('```')[1].split('```')[0];
    }

    try {
      return JSON.parse(content.trim());
    } catch (error) {
      console.error('Failed to parse DeepSeek response:', error);
      return null;
    }
  }
}
```

**Testing:** Create unit tests with mocked API responses

---

### Phase 2: PDF Processing (1 day)

**Options:**

#### Option A: Browser-based PDF Processing (RECOMMENDED)
```typescript
// benchmark-app/lib/pdf/processor.ts
import * as pdfjsLib from 'pdfjs-dist';

export class PDFProcessor {
  async convertToImages(
    pdfFile: File,
    maxPages = 3
  ): Promise<string[]> {
    const arrayBuffer = await pdfFile.arrayBuffer();
    const pdf = await pdfjsLib.getDocument(arrayBuffer).promise;

    const images: string[] = [];
    const pagesToProcess = Math.min(pdf.numPages, maxPages);

    for (let i = 1; i <= pagesToProcess; i++) {
      const page = await pdf.getPage(i);
      const viewport = page.getViewport({ scale: 2.0 }); // High resolution

      const canvas = document.createElement('canvas');
      const context = canvas.getContext('2d')!;
      canvas.width = viewport.width;
      canvas.height = viewport.height;

      await page.render({
        canvasContext: context,
        viewport: viewport
      }).promise;

      const imageBase64 = canvas.toDataURL('image/png').split(',')[1];
      images.push(imageBase64);
    }

    return images;
  }
}
```

**Benefits:**
- No server-side dependencies
- Works in browser
- No Vercel limitations
- Fast and efficient

#### Option B: Server-side with Sharp (Alternative)
```typescript
// benchmark-app/lib/pdf/server-processor.ts
import sharp from 'sharp';
import { fromPath } from 'pdf2pic';

export class ServerPDFProcessor {
  async convertToImages(
    pdfPath: string,
    maxPages = 3
  ): Promise<Buffer[]> {
    const converter = fromPath(pdfPath, {
      density: 300,
      format: 'png',
      width: 2480,
      height: 3508
    });

    const images: Buffer[] = [];

    for (let i = 1; i <= maxPages; i++) {
      const result = await converter(i);
      if (result.buffer) {
        images.push(result.buffer);
      }
    }

    return images;
  }
}
```

**Note:** Option A (browser-based) is preferred for Vercel compatibility

---

### Phase 3: Next.js API Routes (1 day)

**Create:** `benchmark-app/app/api/pdf/extract/route.ts`

```typescript
// benchmark-app/app/api/pdf/extract/route.ts
import { NextRequest, NextResponse } from 'next/server';
import { DeepSeekVisionClient } from '@/lib/deepseek/client';
import { PDFProcessor } from '@/lib/pdf/processor';

export const runtime = 'nodejs'; // or 'edge' if possible

export async function POST(request: NextRequest) {
  try {
    const formData = await request.formData();
    const pdfFile = formData.get('pdf') as File;

    if (!pdfFile) {
      return NextResponse.json(
        { error: 'No PDF file provided' },
        { status: 400 }
      );
    }

    // Convert PDF to images
    const processor = new PDFProcessor();
    const images = await processor.convertToImages(pdfFile, 3);

    // Extract data using DeepSeek
    const apiKey = process.env.DEEPSEEK_API_KEY;
    if (!apiKey) {
      return NextResponse.json(
        { error: 'DeepSeek API key not configured' },
        { status: 500 }
      );
    }

    const client = new DeepSeekVisionClient({
      apiKey,
      maxCostUsd: 0.01, // Safety limit per request
      maxRequestsPerMinute: 60
    });

    // Extract from all images and aggregate
    const results = await Promise.all(
      images.map(img => client.extractFromImage(img))
    );

    // Merge results (take first non-null value for each field)
    const merged = mergeExtractionResults(
      results.filter((r): r is ExtractionResult => r !== null)
    );

    return NextResponse.json({
      success: true,
      data: merged,
      pagesProcessed: images.length
    });

  } catch (error) {
    console.error('PDF extraction error:', error);
    return NextResponse.json(
      { error: error instanceof Error ? error.message : 'Unknown error' },
      { status: 500 }
    );
  }
}

function mergeExtractionResults(results: ExtractionResult[]): ExtractionResult {
  if (results.length === 0) {
    throw new Error('No extraction results to merge');
  }

  const merged = { ...results[0] };

  for (const result of results.slice(1)) {
    for (const [key, value] of Object.entries(result)) {
      if (typeof value === 'object' && value !== null) {
        // Merge nested objects
        for (const [subKey, subValue] of Object.entries(value)) {
          if (merged[key][subKey] === null && subValue !== null) {
            merged[key][subKey] = subValue;
          }
        }
      } else if (Array.isArray(value)) {
        // Merge arrays
        merged[key] = [...new Set([...merged[key], ...value])];
      } else if (merged[key] === null && value !== null) {
        // Use first non-null value
        merged[key] = value;
      }
    }
  }

  return merged;
}
```

---

### Phase 4: Enhanced Matcher (1 day)

**Create:** `benchmark-app/lib/pdf/matcher.ts`

```typescript
// benchmark-app/lib/pdf/matcher.ts
import { SequenceMatcher } from 'difflib';

export interface MatchConfig {
  minConfidence?: number;
}

export interface MatchResult {
  zerezProduct: string;
  pdfMatch: string | null;
  confidence: number;
  details: {
    modelSimilarity: number;
    manufacturerMatch: boolean;
    fieldCompleteness: number;
    powerValid: boolean;
    extractionMethod: string;
    hasJsonData: boolean;
  };
}

export class PDFMatcher {
  private readonly DEFAULT_MIN_CONFIDENCE = 40;

  constructor(
    private config: MatchConfig = {}
  ) {}

  matchProduct(
    product: any,
    pdfIndex: Map<string, any>
  ): MatchResult {
    const modelName = product.modelName || '';
    const normalizedModel = this.normalizeModelName(modelName);

    let bestMatch: string | null = null;
    let bestScore = 0;
    let bestDetails: any = {};

    for (const [pdfPath, pdfData] of pdfIndex.entries()) {
      const pdfName = pdfData.filename.toLowerCase();
      const jsonData = pdfData.json;

      // Calculate model similarity
      let modelSimilarity = this.calculateSimilarity(normalizedModel, pdfName);

      // Check against extracted model if available
      if (jsonData?.identification?.model) {
        const extractedSimilarity = this.calculateSimilarity(
          normalizedModel,
          this.normalizeModelName(jsonData.identification.model)
        );
        modelSimilarity = Math.max(modelSimilarity, extractedSimilarity);
      }

      // Calculate field completeness
      const fieldCompleteness = this.calculateFieldCompleteness(jsonData);

      // Validate power rating
      const [powerValid, powerBoost] = this.validatePowerRating(
        product,
        jsonData
      );

      // Get extraction method
      const extractionMethod = jsonData?.data_source?.extraction_method || 'none';

      // Calculate comprehensive confidence
      const confidence = this.calculateConfidence({
        modelSimilarity,
        manufacturerMatch: pdfData.manufacturer === product.manufacturer,
        fieldCompleteness,
        powerValid,
        powerBoost,
        extractionMethod
      });

      if (confidence > bestScore) {
        bestScore = confidence;
        bestMatch = pdfPath;
        bestDetails = {
          modelSimilarity,
          manufacturerMatch: pdfData.manufacturer === product.manufacturer,
          fieldCompleteness,
          powerValid,
          extractionMethod,
          hasJsonData: !!jsonData
        };
      }
    }

    // Apply minimum threshold
    const minConfidence = this.config.minConfidence ?? this.DEFAULT_MIN_CONFIDENCE;
    if (bestScore < minConfidence) {
      bestMatch = null;
      bestScore = 0;
      bestDetails = {};
    }

    return {
      zerezProduct: modelName,
      pdfMatch: bestMatch,
      confidence: bestScore,
      details: bestDetails
    };
  }

  private normalizeModelName(name: string): string {
    if (!name) return '';

    // Remove common prefixes/suffixes
    name = name.replace(/^ZEREZ-/i, '');
    name = name.replace(/^Model[:\s]+/i, '');

    // Remove special characters but keep alphanumeric and hyphens
    name = name.replace(/[^a-zA-Z0-9\s-]/g, '');

    // Normalize whitespace
    return name.split(/\s+/).join(' ').toLowerCase();
  }

  private calculateSimilarity(str1: string, str2: string): number {
    const matcher = new SequenceMatcher(null, str1.toLowerCase(), str2.toLowerCase());
    return matcher.ratio();
  }

  private calculateFieldCompleteness(jsonData: any): number {
    if (!jsonData) return 0;

    const criticalFields = [
      ['power', 'rated_power_kw'],
      ['efficiency', 'peak_percent'],
      ['physical', 'weight_kg'],
      ['identification', 'model']
    ];

    let filledCount = 0;
    for (const [category, field] of criticalFields) {
      const value = jsonData[category]?.[field];
      if (value !== null && value !== undefined && value !== '') {
        filledCount++;
      }
    }

    return filledCount / criticalFields.length;
  }

  private validatePowerRating(
    product: any,
    jsonData: any
  ): [boolean, number] {
    if (!jsonData) return [true, 0];

    const productPower = product.power?.rated_power_kw;
    const pdfPower = jsonData.power?.rated_power_kw;

    if (!productPower || !pdfPower) return [true, 0];

    const powerDiff = Math.abs(productPower - pdfPower);
    const tolerance = productPower * 0.1;

    if (powerDiff <= tolerance) {
      return [true, 0.3]; // High confidence boost
    } else if (powerDiff <= productPower * 0.3) {
      return [true, 0.1]; // Small boost
    } else {
      return [false, -0.2]; // Penalty
    }
  }

  private calculateConfidence(factors: {
    modelSimilarity: number;
    manufacturerMatch: boolean;
    fieldCompleteness: number;
    powerValid: boolean;
    powerBoost: number;
    extractionMethod: string;
  }): number {
    let score = 0;

    // Model similarity (0-50 points)
    score += factors.modelSimilarity * 50;

    // Manufacturer match (20 points)
    if (factors.manufacturerMatch) {
      score += 20;
    }

    // Field completeness (15 points)
    score += factors.fieldCompleteness * 15;

    // Power validation boost/penalty
    score += factors.powerBoost * 100;

    // Extraction method quality (10 points)
    if (factors.extractionMethod === 'deepseek_vision_api') {
      score += 10;
    } else if (factors.extractionMethod === 'pdf_text_extraction') {
      score += 5;
    }

    // Normalize to 0-100
    return Math.min(100, Math.max(0, (score / 125) * 100));
  }
}
```

---

### Phase 5: Frontend Integration (0.5 days)

**Create:** PDF upload UI component

```typescript
// benchmark-app/components/pdf-upload.tsx
'use client';

import { useState } from 'react';
import { Button } from '@/components/ui/button';

export function PDFUpload() {
  const [file, setFile] = useState<File | null>(null);
  const [loading, setLoading] = useState(false);
  const [result, setResult] = useState<any>(null);

  const handleUpload = async () => {
    if (!file) return;

    setLoading(true);
    try {
      const formData = new FormData();
      formData.append('pdf', file);

      const response = await fetch('/api/pdf/extract', {
        method: 'POST',
        body: formData
      });

      const data = await response.json();
      setResult(data);
    } catch (error) {
      console.error('Upload failed:', error);
    } finally {
      setLoading(false);
    }
  };

  return (
    <div className="space-y-4">
      <input
        type="file"
        accept=".pdf"
        onChange={(e) => setFile(e.target.files?.[0] || null)}
      />

      <Button
        onClick={handleUpload}
        disabled={!file || loading}
      >
        {loading ? 'Extracting...' : 'Extract Data'}
      </Button>

      {result && (
        <pre className="p-4 bg-gray-100 rounded">
          {JSON.stringify(result, null, 2)}
        </pre>
      )}
    </div>
  );
}
```

---

## Migration Checklist

### Setup
- [ ] Install required npm packages
  - [ ] `pdfjs-dist` (PDF processing)
  - [ ] `difflib` (string similarity)
  - [ ] `zod` (validation)

### Core Implementation
- [ ] Create `lib/deepseek/client.ts`
  - [ ] API integration
  - [ ] Rate limiting
  - [ ] Cost controls
  - [ ] Retry logic
  - [ ] Error handling
- [ ] Create `lib/deepseek/types.ts`
  - [ ] TypeScript interfaces
  - [ ] Zod schemas
- [ ] Create `lib/pdf/processor.ts`
  - [ ] Browser-based PDF to image
  - [ ] High-resolution rendering
- [ ] Create `lib/pdf/matcher.ts`
  - [ ] Multi-factor confidence scoring
  - [ ] Model normalization
  - [ ] Field completeness

### API Routes
- [ ] Create `app/api/pdf/extract/route.ts`
  - [ ] File upload handling
  - [ ] PDF processing
  - [ ] DeepSeek extraction
  - [ ] Result aggregation
- [ ] Create `app/api/pdf/match/route.ts`
  - [ ] PDF matching logic
  - [ ] Confidence scoring

### Frontend
- [ ] Create PDF upload component
- [ ] Add to existing import wizard
- [ ] Progress indicators
- [ ] Error handling

### Testing
- [ ] Unit tests for DeepSeek client
- [ ] Unit tests for matcher
- [ ] Integration tests for API routes
- [ ] E2E tests with real PDFs
- [ ] Performance testing

### Documentation
- [ ] Update API documentation
- [ ] Add TypeScript usage examples
- [ ] Migration notes
- [ ] Troubleshooting guide

### Deployment
- [ ] Set DEEPSEEK_API_KEY env variable in Vercel
- [ ] Test on Vercel preview deployment
- [ ] Monitor cold start times
- [ ] Verify cost controls work
- [ ] Production deployment

---

## NPM Packages Needed

```json
{
  "dependencies": {
    "pdfjs-dist": "^4.0.0",
    "difflib": "^0.2.4"
  },
  "devDependencies": {
    "@types/pdfjs-dist": "^2.10.0"
  }
}
```

---

## Environment Variables

```env
# .env.local
DEEPSEEK_API_KEY=sk-xxxxx

# Optional
DEEPSEEK_BASE_URL=https://api.deepseek.com/v1
DEEPSEEK_MAX_COST_USD=1.0
DEEPSEEK_MAX_REQUESTS_PER_MINUTE=60
```

---

## Estimated Timeline

| Phase | Task | Effort | Dependencies |
|-------|------|--------|--------------|
| 1 | DeepSeek Client | 2 days | None |
| 2 | PDF Processor | 1 day | None |
| 3 | API Routes | 1 day | Phase 1, 2 |
| 4 | Matcher | 1 day | None |
| 5 | Frontend | 0.5 days | Phase 3 |
| Testing | Unit + Integration | 1 day | All phases |
| **Total** | | **6.5 days** | |

**Buffer:** Add 1-2 days for unexpected issues

**Total Estimate:** 7-8 days (1.5 weeks)

---

## Benefits of TypeScript Migration

### Technical
- ✅ Works on Vercel serverless
- ✅ Faster cold starts
- ✅ Better debugging
- ✅ Type safety end-to-end
- ✅ Integrated with Next.js
- ✅ No Python runtime needed

### Development
- ✅ Easier to maintain
- ✅ Better IDE support
- ✅ Consistent codebase
- ✅ Team expertise in TypeScript
- ✅ Better testing tools

### Operations
- ✅ Simpler deployment
- ✅ No Python dependencies
- ✅ Better monitoring
- ✅ Vercel-native support

---

## Risk Assessment

### Low Risk
- API integration (straightforward HTTP calls)
- Rate limiting (well-documented patterns)
- Type definitions (clear from Python implementation)

### Medium Risk
- PDF processing performance (browser-based may be slower)
- Image quality (need to verify canvas rendering)
- Concurrent requests (need to test rate limiting)

### Mitigation
- Test with real PDFs early
- Benchmark browser PDF rendering
- Add comprehensive error handling
- Implement progressive enhancement (fallback to server-side if needed)

---

## Success Criteria

Migration is complete when:

- [ ] All Python features replicated in TypeScript
- [ ] API routes deployed on Vercel
- [ ] Tests passing (unit + integration + E2E)
- [ ] Performance acceptable (<3s for PDF extraction)
- [ ] Cost controls working (verified with test API calls)
- [ ] Documentation updated
- [ ] Production deployment successful
- [ ] Python scripts deprecated/removed from production path

---

## Next Steps

### Immediate (Start Migration)
1. Create feature branch: `feat/deepseek-typescript`
2. Install required npm packages
3. Start with Phase 1 (DeepSeek client)
4. Create unit tests as you go

### Short Term (This Week)
1. Complete Phases 1-3 (core functionality)
2. Test with real API and PDFs
3. Verify rate limiting and cost controls
4. Create PR for review

### Medium Term (Next Week)
1. Complete Phases 4-5 (matcher + frontend)
2. Integration testing
3. Deploy to Vercel preview
4. Performance testing
5. Production deployment

---

## Questions to Resolve

1. **PDF Processing:** Browser-based vs server-side?
   - **Recommendation:** Browser-based (Vercel-friendly)

2. **Where to store extracted JSON?**
   - **Options:**
     - Git repository (current approach)
     - Vercel Blob Storage
     - External database
   - **Recommendation:** Keep in Git for now (consistent with current design)

3. **Caching strategy?**
   - Use Vercel KV or similar for API response caching
   - Cache based on PDF hash
   - **Recommendation:** Add in Phase 2 of deployment

4. **Batch processing?**
   - **Current:** One PDF at a time
   - **Future:** Queue system for bulk processing
   - **Recommendation:** Single PDF first, add batching later

---

## References

- **Python Implementation:** `.memory-bank/deepseek_implementation_complete.md`
- **Production Status:** `.memory-bank/deepseek_production_ready.md`
- **Platform Requirements:** `.memory-bank/platform_requirements.md`
- **DeepSeek API Docs:** https://api-docs.deepseek.com/

---

**Status:** Ready to start migration
**Owner:** Development Team
**Priority:** HIGH
**Target Completion:** 1.5-2 weeks from start
