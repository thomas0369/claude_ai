#!/usr/bin/env python3
"""
ZEREZ JSON Saver
================

Saves ZEREZ unit data to JSON files.
Designed to work with data already fetched from GraphQL search.

This script receives complete unit data from the search results
and saves each unit to an individual JSON file with all 58 fields.

Usage:
    python3 zerez_json_saver.py --units '[...]' --output-dir data/zerez/imports --stream-progress
"""

import argparse
import json
import logging
import sys
import time
from pathlib import Path
from typing import Dict, List, Optional
from zerez_import_base import (
    ZEREZImporterBase,
    parse_unit_input,
    validate_output_directory
)

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class ZEREZJSONSaver(ZEREZImporterBase):
    """Save ZEREZ product data to JSON files."""

    def __init__(self, output_dir: Path, stream_progress: bool = False, single_file: bool = False):
        super().__init__(output_dir, stream_progress)
        self.single_file = single_file
        self.collected_units: List[Dict] = []

    def process_unit(self, unit_data: Dict, model_name: str) -> bool:
        """
        Save a single unit to JSON file (or collect for bulk save).

        Args:
            unit_data: Complete unit data from GraphQL (all 58 fields)
            model_name: Display name for logging

        Returns:
            True if saved successfully, False otherwise
        """
        unit_id = unit_data.get('id')

        if not unit_id:
            error_msg = f"Invalid data for {model_name}: Unit data missing 'id' field"
            logger.error(f"‚úó {error_msg}")
            self.stats.add_error(error_msg)
            return False

        # Add import metadata
        enhanced_data = {
            **unit_data,
            'importedAt': time.strftime('%Y-%m-%d %H:%M:%S'),
            'importMethod': 'graphql_api_search',
            'apiVersion': '1.0',
        }

        # If single-file mode, collect units instead of saving individually
        if self.single_file:
            self.collected_units.append(enhanced_data)
            return True

        # Otherwise, save individual file
        success, error = self.writer.save_json(unit_id, enhanced_data, model_name)

        if success:
            self.stats.increment('saved_files')
            return True
        else:
            logger.error(f"‚úó {error}")
            self.stats.add_error(error)
            return False

    def finalize(self) -> tuple[bool, Optional[str]]:
        """
        Finalize the export (save bulk file if in single-file mode).

        Returns:
            (success: bool, filename: Optional[str])
        """
        if not self.single_file or not self.collected_units:
            return True, None

        # Save all collected units to a single file
        metadata = {
            'importedAt': time.strftime('%Y-%m-%d %H:%M:%S'),
            'totalProducts': len(self.collected_units),
            'importMethod': 'graphql_api_search',
            'apiVersion': '1.0'
        }

        success, error, filename = self.writer.save_bulk_json(self.collected_units, metadata)

        if success:
            self.stats.increment('saved_files')
            return True, filename
        else:
            logger.error(f"‚úó {error}")
            self.stats.add_error(error)
            return False, None


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description='Save ZEREZ product data to JSON files',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Save products from search results
  python3 zerez_json_saver.py \\
    --units '[{"id":"uuid1","modelName":"Model 1",...}]' \\
    --output-dir data/zerez/imports \\
    --stream-progress

Input Format:
  --units expects a JSON array of complete unit objects from GraphQL search.
  Each unit should contain all 58 fields returned by the API.

Output Format:
  Each product is saved as {uuid}.json with:
  - All original fields from GraphQL
  - importedAt timestamp
  - importMethod metadata
        """
    )
    parser.add_argument('--units', required=True, help='JSON array of complete unit data')
    parser.add_argument('--output-dir', required=True, help='Output directory for JSON files')
    parser.add_argument('--stream-progress', action='store_true', help='Stream progress updates (for SSE)')
    parser.add_argument('--single-file', action='store_true', help='Save all products to a single timestamped file instead of individual files')

    args = parser.parse_args()

    try:
        # Parse and validate input using shared utility
        units, _ = parse_unit_input(args.units)
        output_dir = Path(args.output_dir)
        validate_output_directory(output_dir)

        # Run saver
        saver = ZEREZJSONSaver(output_dir, stream_progress=args.stream_progress, single_file=args.single_file)
        result = saver.process_units(units)

        # Finalize (saves bulk file if in single-file mode)
        finalize_success, filename = saver.finalize()
        if filename:
            result['output_file'] = filename
            logger.info(f"\nüìÅ Export saved to: {filename}")

        # Print final result (if not streaming)
        if not args.stream_progress:
            print(json.dumps(result, indent=2))

        # Exit with error code if any failures
        sys.exit(1 if (result['failed'] > 0 or not finalize_success) else 0)

    except ValueError as e:
        print(json.dumps({'error': str(e)}), file=sys.stderr)
        sys.exit(1)

    except KeyboardInterrupt:
        logger.warning("\n‚ö†Ô∏è  Save interrupted by user")
        sys.exit(130)

    except Exception as e:
        logger.error(f"‚ùå Fatal error: {e}")
        print(json.dumps({'error': str(e)}), file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()
